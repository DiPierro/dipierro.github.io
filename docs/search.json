[
  {
    "objectID": "updates.html",
    "href": "updates.html",
    "title": "Updates",
    "section": "",
    "text": "Code: A neat mail merge trick in R\n\n\n\ncode\n\n\n\n\n\n\nJul 26, 2025\n\n\n\n\n\n\n\nCode: Visualizing New Jersey rest stops\n\n\n\ncode\n\n\n\n\n\n\nJun 27, 2025\n\n\n\n\n\n\n\nCode: Scraping DOGE\n\n\n\ncode\n\n\n\n\n\n\nJun 8, 2025\n\n\n\n\n\n\n\nListening: Marcia Griffiths, Yukihiro Takahashi, Pete Seeger\n\n\n\nlistening\n\n\n\n\n\n\nJun 5, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "updates/listening-2025-06/index.html",
    "href": "updates/listening-2025-06/index.html",
    "title": "Listening: Marcia Griffiths, Yukihiro Takahashi, Pete Seeger",
    "section": "",
    "text": "This is the first post in an occasional series sharing songs I heard and liked. Enjoy!\n Marcia Griffiths - “Everywhere”\n Yukihiro Takahashi - “Drip Dry Eyes”\n Pete Seeger - “The Dove”"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\nHello\nMy name is Amy DiPierro. I am a data journalist reporting in the public interest.\nMy job is to look at the world and report what I see. In pursuit of that goal, I borrow liberally from fields like statistics and computer programming, and do the usual number-dialing and door-knocking, too.\nI work at EdSource, California’s largest education newsroom, where I lead our coverage of California State University. I was previously a data journalist at the Center for Public Integrity, where my reporting received an honorable mention in the Philip Meyer Journalism Award contest. I also played a small role in a very cool Big Local News project called civic-scraper.\nI studied history and economics at Swarthmore College and hold a master’s degree in journalism from Stanford University, where I was a Knight-Hennessy Scholar.\nYou can catch me discussing my work in places like KPBS and Capital Public Radio, as well as journalism conferences like NICAR and IRE.\n\n\nKudos\n\nSpecial citation, Philip Meyer Journalism Award - Investigative Reporters & Editors (2023)\nShortlist - Sigma Awards (2023)\nBreaking Barriers Award - Institute for Nonprofit News (2023)\nDateline Awards - Winner, Online Series - Washington, D.C., Chapter of the Society of Professional Journalists (2023)\nStewart B. McKinney Award - Human Right to Housing Awards - National Homelessness Law Center (2023)\n\n\n\nSkills\n\nComputer programming and web scraping with Python\nData analysis with R and SQL\nStructured data extraction, categorization and more with large language models\nAutomation with GitHub Actions\nData visualization with Datawrapper and Flourish\nMap making with QGIS and R\nStatic site web development with Quarto\nVersion control with Git and GitHub\nPublic records requests"
  },
  {
    "objectID": "updates/nj-rest-stops/index.html",
    "href": "updates/nj-rest-stops/index.html",
    "title": "Code: Visualizing New Jersey rest stops",
    "section": "",
    "text": "While road-tripping in New Jersey this summer, I put together this quick map showing all of the rest stops on the New Jersey Turnpike and Garden State Parkway – from the James Gandolfini Service Area in the northeast corner of the state, all the way down to the John Fenwick Service Plaza near Delaware.\n\n\n\n\n\n\nSources: NJGIN Open Data Portal, New Jersey Turnpike Authority, Wikipedia, Google Maps\nIf you find yourself traveling the same roads, you may also enjoy:\n\nGlenn Jones - “My Garden State”\nFountains of Wayne - “The Valley of Malls”\nBruce Springsteen - “Blue Highway”\n\nFound a bug? Got a comment, criticism or suggestion for improvement? Drop me a note: adipierro.edsource.org."
  },
  {
    "objectID": "updates/doge/index.html",
    "href": "updates/doge/index.html",
    "title": "Code: Scraping DOGE",
    "section": "",
    "text": "I’ve been experimenting with GitHub Actions to automatically scrape the DOGE API once a week. This should make it possible to compare snapshots of each endpoint to one another over time.\nYou can clone the repository and run the script doge.sh from the command line to download a JSON file of all the contracts, grants, leases or payments displayed on the DOGE website. Or you can grab the link to the most-recent JSON file the scraper has downloaded and analyze from there.\nFor example, here’s how you might pull down the latest contracts.json file using R:\n\n# Libraries\nlibrary(tidyverse)\nlibrary(jsonlite)\n\nurl_gist &lt;- \"https://raw.githubusercontent.com/DiPierro/doge/refs/heads/main/contracts.json\"\nraw_contracts &lt;- fromJSON(curl::curl(url_gist))\ncontracts &lt;- map_dfr(raw_contracts, bind_rows)\n\ncontracts %&gt;%\n  head(5) %&gt;% \n  select(1:4) %&gt;% \n  knitr::kable()\n\n\n\n\n\n\n\n\n\n\npiid\nagency\nvendor\nvalue\n\n\n\n\n140D0424F0005\nDepartment of the Interior\nFamily Endeavors, Inc\n3329900357\n\n\n2032H524A00020\nDepartment of Treasury\nCENTENNIAL TECHNOLOGIES INC.\n1900000000\n\n\nHT001523D0002\nDepartment of Defense\nA1FEDIMPACT\n1826530973\n\n\nFA872624FB071\nDepartment of Defense\nAccenture\n1491605888\n\n\nFA701420D0007\nDepartment of Air Force\nDeloitte Consulting LLP\n2750000000\n\n\n\n\n\nA word of caution: several news reports have called out errors in DOGE’s accounting of its government restructuring efforts, so take care when working with this data. Here’s some further reading:\n\nThe New York Times: DOGE Makes Its Latest Errors Harder to Find\nCBS News: DOGE continues to publish misleading or inaccurate claims on its “Wall of Receipts”\n\nFound a bug? Got a comment, criticism or suggestion for improvement? Drop me a note: adipierro.edsource.org."
  },
  {
    "objectID": "updates/mail-merge/index.html",
    "href": "updates/mail-merge/index.html",
    "title": "Code: A neat mail merge trick in R",
    "section": "",
    "text": "While reporting a recent story, I wanted to send customized versions of the same email to dozens of potential sources. It was a classic use case for mail merge and, since I was already working with a spreadsheet that included prospective sources’ names and emails in R, I wondered: Could I run a mail merge without ever leaving RStudio?\nIt turns out the answer to this question is a resounding “yes” – and here’s how I did it.\n\n1: Configure Gmail.\nThis was the trickiest part. I started by setting up two-factor authentication and then created an app password. I’ll use the password in the final step to send emails from R.\nNext, to avoid including my app password in published scripts, I stashed it in my .Renviron file, saving it as the environmental variable GMAIL_APP_PW. If you get tripped up looking for your .Renviron, you can always pull it with usethis::edit_r_environ().\n\n\n2: Format emails.\nFrom there, all I had to do was read in a csv file with names and emails, create an email template and use string substitution to customize each message.\n\n# Libraries\nlibrary(tidyverse)\nlibrary(curl)\nlibrary(here)\n\n# Parameters\nfile_in &lt;- here(\"updates/mail-merge/example.csv\")\npw &lt;- Sys.getenv(\"GMAIL_APP_PW\") \nsender &lt;- \"adipierro@edsource.org\"\n\n# Code\n\n## Read in file of recipients\nrecipients &lt;- read_csv(file_in)\n\n## Write an email template\ntemplate &lt;- \"\nFrom: 'Amy DiPierro' &lt;adipierro@edsource.org&gt;\nTo: '{first_name} {last_name}' &lt;{email}&gt;\nSubject: Hello, {first_name}!\n\nDear {first_name},\n\nHow's it going at {employer}?\n\nCheers,\nAmy\n\"\n\n# Use string formatting to customize each email.\nmessage &lt;- recipients %&gt;% str_glue_data(template)\n\n# Extract list of recipients' emails\nemails &lt;- recipients %&gt;% pull(email)\n\nHere’s the original data I used to send test emails to myself:\n\n\n\n\n\nfirst_name\nlast_name\nemail\nemployer\n\n\n\n\nAmy\nDiPierro\nadipierro@edsource.org\nEdSource\n\n\nMya\nDePriori\nadipierro@edsource.org\nCodeUser\n\n\n\n\n\nAnd here’s an example of how the email template looks after string formatting:\n\n\nFrom: 'Amy DiPierro' &lt;adipierro@edsource.org&gt;\nTo: 'Mya DePriori' &lt;adipierro@edsource.org&gt;\nSubject: Hello, Mya!\n\nDear Mya,\n\nHow's it going at CodeUser?\n\nCheers,\nAmy\n\n\n\n\n3: Send emails!\nFinally, I used the send_mail function from R’s curl library to email each customized message to the right recipient. In the code below, I wrap send_mail in the purrr function map2, which loops through the list of customized messages and emails simultaneously.\n\n# Send all emails\nmap2(\n  .x = message,\n  .y = emails,\n  .f = ~ send_mail(\n    mail_from = sender,\n    mail_rcpt = .y,\n    message = .x,\n    smtp_server = \"smtps://smtp.gmail.com\",\n    username = sender,\n    password  = pw,\n    verbose = FALSE\n  )\n)\n\nAnd that’s it. Within a few moments, my test emails hit my inbox.\nFound a bug? Got a comment, criticism or suggestion for improvement? Drop me a note: adipierro.edsource.org."
  }
]